{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DA6401 Assignment 1\n",
    "#### Achyutha M. - PH21B004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from utils import wandb_helper, helper_functions, neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_entity = \"bullseye2608-indian-institute-of-technology-madras\"\n",
    "wandb_project = \"PH21B004_DA6401-Assignment-1\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = helper_functions.load_data('fashion_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log image examples to wandb\n",
    "wandb_helper.log_images(X_train, y_train, entity=wandb_entity, project=wandb_project)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemented and initialised the class NeuralNetwork\n",
    "nn = neural_network.NeuralNetwork(\n",
    "    layer_sizes=[784, 64, 64, 10],\n",
    "    activation_functions=['relu', 'relu', 'softmax'],\n",
    "    weight_decay=0.0,\n",
    "    weight_init='xavier',\n",
    ")\n",
    "\n",
    "# Testing initialised model\n",
    "y_init_pred = nn.forward_propagation(X_train)[0][-1]\n",
    "init_accuracy = nn.compute_accuracy_from_predictions(y_init_pred, y_train)\n",
    "\n",
    "print(f\"Accuracy of Neural Network before training: {init_accuracy :<f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "optimizer = {\n",
    "    'name': 'adam',\n",
    "    'learning_rate': 0.01,\n",
    "    'beta1': 0.9,\n",
    "    'beta2': 0.999,\n",
    "    'epsilon': 1e-8\n",
    "}\n",
    "\n",
    "nn.set_optimizer(optimizer_dict=optimizer)\n",
    "\n",
    "history = nn.train(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_val=X_val,\n",
    "    y_val=y_val,\n",
    "    batch_size=64,\n",
    "    num_epochs=10,\n",
    "    loss_type='cross_entropy',\n",
    ")\n",
    "\n",
    "nn.plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compute_accuracy(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create New sweep\n",
    "import yaml\n",
    "\n",
    "with open(\"sweep_config.yaml\", \"r\") as file:\n",
    "        sweep_config = yaml.safe_load(file)\n",
    "\n",
    "run_count = 2\n",
    "flag_restart_sweep, sweep_id = False, 'g0rcwx3e'\n",
    "\n",
    "if flag_restart_sweep:\n",
    "        \n",
    "        sweep_id = wandb.sweep(sweep_config, \n",
    "                entity=wandb_entity,\n",
    "                project=wandb_project)\n",
    "        trainer = wandb_helper.WandbTrainer()\n",
    "\n",
    "        wandb.agent(sweep_id, trainer.train, count=run_count)\n",
    "        flag_restart_sweep = False\n",
    "else:\n",
    "        sweep_id_cont = '/'.join([wandb_entity, wandb_project, sweep_id])\n",
    "        trainer = wandb_helper.WandbTrainer()\n",
    "        \n",
    "        wandb.agent(sweep_id_cont, trainer.train, count=run_count)\n",
    "\n",
    "wandb.finish()\n",
    "wandb.teardown()\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f'Succesfully ran sweep of {run_count} runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimal model configuration multiple times\n",
    "def run_multiple_experiments(variation, log_aggregate_confusion_matrix=True):\n",
    "    \n",
    "    \n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    # Lists to store results from all runs\n",
    "    all_metrics = []\n",
    "    all_cms = []\n",
    "    all_y_preds = []\n",
    "    run_ids = []\n",
    "    \n",
    "    # Create a group ID for all runs\n",
    "    group_id = f\"optimal-config-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    \n",
    "    # Set changes in runs\n",
    "    \n",
    "    num_runs = len(variation)\n",
    "    \n",
    "    # Run the model multiple times\n",
    "    for run_id in tqdm(range(num_runs)):\n",
    "        print(f'Run {run_id+1} of {num_runs}')\n",
    "        # Set a different random seed for each run\n",
    "        np.random.seed(42 + run_id)\n",
    "        config = helper_functions.OptimalConfig(**variation[run_id])\n",
    "        \n",
    "        # Initialize a new wandb run\n",
    "        run = wandb.init(\n",
    "            entity=wandb_entity,\n",
    "            project=wandb_project,\n",
    "            name=f\"optimal-run-{run_id+1}\",\n",
    "            tags=[\"optimal-config\"],\n",
    "            group=group_id,\n",
    "            config=config,\n",
    "            reinit=True\n",
    "        )\n",
    "            # wandb.config.update(config)\n",
    "        config.print_config()\n",
    "        \n",
    "        \n",
    "        layer_sizes = [784] + [config.hidden_size]*config.num_layers + [10]\n",
    "        activation_functions = [config.activation]*config.num_layers + ['softmax']\n",
    "        \n",
    "        nn = neural_network.NeuralNetwork(layer_sizes=layer_sizes, \n",
    "                        activation_functions=activation_functions,\n",
    "                        weight_init=config.weight_init, \n",
    "                        weight_decay=config.weight_decay)\n",
    "        \n",
    "        wandb_callback = wandb_helper.WandbCallback()\n",
    "        \n",
    "        optimizer = helper_functions.get_optimizer(config.optimizer, config.learning_rate)\n",
    "        nn.set_optimizer(optimizer)\n",
    "        \n",
    "        nn.train(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            batch_size=config.batch_size,\n",
    "            num_epochs=config.epochs,\n",
    "            loss_type=config.loss,\n",
    "            log_every=1000,\n",
    "            callback=wandb_callback\n",
    "        )\n",
    "        \n",
    "        test_accuracy = nn.compute_accuracy(X_val, y_val)\n",
    "        wandb.log({\"test_accuracy\": test_accuracy})\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loss = nn.compute_loss(nn.predict(X_val), y_val)\n",
    "        test_acc = nn.compute_accuracy(X_val, y_val)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred_probs = nn.predict(X_val)\n",
    "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "        \n",
    "        # Store predictions\n",
    "        all_y_preds.append(y_pred)\n",
    "        \n",
    "        # Create and log confusion matrix\n",
    "        cm_file, cm, precision, recall, f1 = helper_functions.plot_confusion_matrix(y_val, y_pred, run_id)\n",
    "        all_cms.append(cm)\n",
    "        \n",
    "        # Log confusion matrix image\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(cm_file)})\n",
    "        \n",
    "        # Log interactive confusion matrix\n",
    "        wandb.log({\"confusion_matrix_plot\": wandb.plot.confusion_matrix(\n",
    "            probs=y_pred_probs,\n",
    "            y_true=y_val,\n",
    "            class_names=class_names\n",
    "        )})\n",
    "        \n",
    "        # Log metrics\n",
    "        run_metrics = {\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_acc,\n",
    "            'run_id': run_id + 1\n",
    "        }\n",
    "    \n",
    "        \n",
    "        # Log all metrics\n",
    "        wandb.log(run_metrics)\n",
    "        \n",
    "        # Store metrics for aggregate analysis\n",
    "        all_metrics.append(run_metrics)\n",
    "        run_ids.append(run.id)\n",
    "        \n",
    "        \n",
    "        # Finish the run\n",
    "        wandb.finish()\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    if log_aggregate_confusion_matrix:\n",
    "        # Create an aggregate analysis run\n",
    "        run = wandb.init(\n",
    "            entity=wandb_entity,\n",
    "            project=wandb_project,\n",
    "            name=f\"aggregate-analysis-{num_runs}-runs\",\n",
    "            tags=[\"aggregate\", \"analysis\"],\n",
    "            group=group_id\n",
    "        )\n",
    "        \n",
    "        # Calculate average confusion matrix\n",
    "        avg_cm = np.mean(all_cms, axis=0)\n",
    "        std_cm = np.std(all_cms, axis=0)\n",
    "        \n",
    "        # Create and log aggregate confusion matrix\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        avg_cm_normalized = avg_cm.astype('float') / avg_cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        fig = helper_functions.create_plotly_confusion_matrix(avg_cm[:, ::-1], class_names, num_runs=num_runs)\n",
    "        \n",
    "        helper_functions.log_plotly_confusion_matrix_to_wandb(fig, run_id=0)\n",
    "        \n",
    "        \n",
    "        avg_cm_df = pd.DataFrame(avg_cm_normalized, index=class_names, columns=class_names)\n",
    "        \n",
    "        sns.heatmap(avg_cm_df, annot=True, fmt='.2f', cmap='viridis', \n",
    "                    linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "        \n",
    "        # Calculate aggregate metrics\n",
    "        accuracies = [m['test_accuracy'] for m in all_metrics]\n",
    "        mean_acc = np.mean(accuracies)\n",
    "        std_acc = np.std(accuracies)\n",
    "        \n",
    "        plt.title(f'Aggregate Confusion Matrix (17 Runs)\\nMean Accuracy: {mean_acc:.4f} Â± {std_acc:.4f}', fontsize=16)\n",
    "        plt.ylabel('True Label', fontsize=12)\n",
    "        plt.xlabel('Predicted Label', fontsize=12)\n",
    "        \n",
    "        # Save and log the aggregate confusion matrix\n",
    "        agg_cm_file = \"./plots/aggregate_confusion_matrix.png\"\n",
    "        plt.savefig(agg_cm_file, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        wandb.log({\"aggregate_confusion_matrix\": wandb.Image(agg_cm_file)})\n",
    "        \n",
    "        # Log aggregate metrics\n",
    "        agg_metrics = {\n",
    "            'mean_accuracy': mean_acc,\n",
    "            'std_accuracy': std_acc,\n",
    "            'min_accuracy': min(accuracies),\n",
    "            'max_accuracy': max(accuracies),\n",
    "            'num_runs': num_runs\n",
    "        }\n",
    "        \n",
    "        # Create a summary table with links to all runs\n",
    "        run_table = wandb.Table(columns=[\"Run ID\", \"Accuracy\"])\n",
    "        for i, (run_id, metrics) in enumerate(zip(run_ids, all_metrics)):\n",
    "            run_table.add_data(i+1, metrics['test_accuracy'])\n",
    "        \n",
    "        wandb.log({\"runs_summary\": run_table})\n",
    "        wandb.log(agg_metrics)\n",
    "        \n",
    "        # Finish the aggregate run\n",
    "        wandb.finish()\n",
    "    \n",
    "    wandb.teardown()\n",
    "    return all_metrics, all_cms, all_y_preds, agg_cm_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation = [\n",
    "        {},\n",
    "        # {'loss': 'mean_squared_error'},\n",
    "        {'batch_size': 32, 'num_layers': 4},\n",
    "        {'epochs':15, 'batch_size': 128, 'num_layers': 5},\n",
    "    ]\n",
    "\n",
    "_, _, _, agg_cm_file = run_multiple_experiments(variation=variation, log_aggregate_confusion_matrix=True)\n",
    "\n",
    "clear_output(wait=True)\n",
    "plt.figure(figsize=(10, 8), dpi=200)\n",
    "img_read = mpimg.imread(agg_cm_file)\n",
    "plt.imshow(img_read)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"All {len(variation)} runs completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store models and histories\n",
    "ce_models = []\n",
    "mse_models = []\n",
    "ce_histories = []\n",
    "mse_histories = []\n",
    "\n",
    "num_runs = 5\n",
    "\n",
    "# Run each model num_runs times\n",
    "config_1 = helper_functions.OptimalConfig()\n",
    "config_2 = helper_functions.OptimalConfig(loss='mean_squared_error', batch_size=32, optimizer='rmsprop')\n",
    "epochs = config_1.epochs\n",
    "\n",
    "for i in tqdm(range(num_runs)):\n",
    "    # Train CE model\n",
    "    nn_ce, history_ce = neural_network.nn_from_config(config=config_1, \n",
    "                                        wandb_callback=None, \n",
    "                                        X_train=X_train, \n",
    "                                        y_train=y_train, \n",
    "                                        X_val=X_val, \n",
    "                                        y_val=y_val)\n",
    "    ce_models.append(nn_ce)\n",
    "    ce_histories.append(history_ce)\n",
    "    \n",
    "    # Train MSE model\n",
    "    nn_mse, history_mse = neural_network.nn_from_config(config=config_2, \n",
    "                                        wandb_callback=None, \n",
    "                                        X_train=X_train, \n",
    "                                        y_train=y_train, \n",
    "                                        X_val=X_val, \n",
    "                                        y_val=y_val)\n",
    "    mse_models.append(nn_mse)\n",
    "    mse_histories.append(history_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = helper_functions.plot_loss_comparison(\n",
    "    ce_histories=ce_histories,\n",
    "    ce_models=ce_models,\n",
    "    mse_histories=mse_histories,\n",
    "    mse_models=mse_models,\n",
    "    epochs=config_1.epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
